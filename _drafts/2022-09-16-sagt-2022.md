---
layout: post
title: Trip Report -- The 15th International Symposium on Algorithmic Game Theory (SAGT 2022)
date: 2022-09-16
---

{% include mathjax.html %}

Over the past few days I attended the [15th International Symposium on Algorithmic Game Theory](https://www.essex.ac.uk/events/2022/09/11/sagt-2022), otherwise known as SAGT 2022, hosted by the University of Essex. It runs every year and its aim is to bring together researchers from computer science, mathematics, economics, operations research, among others, to discuss recent advances at the intersection of algorithms with game theory. The talks were held in the STEM building at the university's Colchester campus.

{% 
	include image.html
	url="/assets/sagt-2022/stem-building.jpg"
	width="400"
	description="The STEM building where the talks were hosted."
%}

## Tutorial 1: _Total Search Problems in Game Theory and Economics_

Monday was reserved for two tutorials which served to map out the lay of the land of recent work in total search problems and fair division in computer science. The first, on _Total Search Problems in Game Theory and Economics_ and given by Aris Filos-Ratsikas and Alexandros Hollender, gave an overview of several complexity classes from TFNP. Contrasted to a decision problem, where we are interested in deciding if a solution to a particular input exists,[^1] for a function problem we are also interested in returning a solution (if one exists). For the class TFNP -- short for **T**otal **F**unction **N**on-deterministic **P**olynomial time -- we must find a solution to a _total_ function problem, where totality indicates that for every input a solution is guaranteed to exist. 

The subclasses of TFNP describe the principle by which a solution's existence is guaranteed for any input. Here are a few:
- PPA (for **P**olynomial **P**arity **A**rgument): existence is guaranteed by the fact that any graph whose nodes have degree at most two must have an even number of leaves.
- PPAD (for **PPA** on **D**irected graphs): existence is guaranteed by the fact that a directed graph with an unbalanced (in-degree unequal to out-degree) node must have another unbalanced node
- PPP (for **P**olynomial **P**igeonhole **P**rinciple): existence is guaranteed by the Pigeonhole Principle which states that if $$n$$ items are to be put into $$m < n$$ containers then there must be at least one container with more than one item.
- PLS (for **P**olynomial **L**ocal **S**earch): existence is guaranteed by the fact that any directed acyclic graph must have a sink.

### Part I: How to choose a candidate class for hardness

The main takeaway from the first part of the tutorial was that the proof of guaranteed existence of some mathematical object may give hints as to how to classify the function problem corresponding to _finding_ such an object. Now that is a hideously abstract sentence so I will break it down using some of the examples Aris gave. Let's start with PPAD-completeness.[^2] 

The canonical complete problem for PPAD is the following. Suppose we are given a description of an exponentially large directed graph whereby we cannot see the whole graph at once, but instead we can only see a node's neighbours by querying two circuits (one for predecessors and the other for successors). Furthermore the graph is such that each node has in-degree and out-degree at most one. Now, given a source in this graph the goal is to find a sink or another source. 

The name of this problem is `EndOfALine`. How does this help us? Well since it is PPAD-complete, if we can reduce it to some other problem `L` then we will have shown that `L` is PPAD-hard. But why does this matter? In 1951 John Nash proved that every finite non-cooperative game admits a Nash Equilibrium, a strategy profile in which no player may increase her expected utility by unilaterally deviating from her current strategy. He proved this using Brouwer's fixed point theorem, which says that any function $$f : S \to S$$ from a compact convex set $$S$$ to itself must have a fixed point $$x = f(x)$$ where $$f$$ maps $$x$$ to itself. Sperner's lemma can be viewed as a discretised version of this and it states that every Sperner colouring (details found [here](https://en.wikipedia.org/wiki/Sperner's_lemma#Statement)) of a triangulation of an $$n$$-dimensional simplex must contain a panchromatic triangle, or a triangle in which each vertex is coloured using a unique colour from the $$n+1$$ colours available. Just like you can prove the existence of Nash Equilibria using Brouwer's fixed point theorem, you can prove the existence of approximate Nash Equilibria using Sperner's lemma.

The computational problems associated with these two existence theorems are `BROUWER` and `SPERNER`. In `BROUWER` we are given an arithmetic circuit computing the function $$f$$ and we wish to output a fixed point, and in `SPERNER` we are given a polynomial colouring circuit for a triangulation of a simplex and we wish to output a pancrhomatic triangle. Now we want to classify the problem of finding an $$\varepsilon$$-approximate Nash Equilibrium[^3] into a subclass of TFNP, but which one? Conveniently `SPERNER` is PPAD-complete, and since existence of approximate Nash Equilibria can be proven using Sperner's lemma, it makes sense that we might be able to prove PPAD-completeness by reducing `SPERNER` to `εNashEquilibrium`. This is in fact exactly what happens! Now since `EndOfALine` is reducible to `SPERNER` and `SPERNER` is reducible to finding an approximate Nash Equilibrium, finding an approximate Nash Equilibrium is therefore PPAD-complete. The chain of reductions is the following:

$$
\texttt{EndOfALine} \le_p 
\texttt{SPERNER} \le_p 
\texttt{εNashEquilibrium}, \texttt{OTHER}
$$

This was the takeaway for the first part of the tutorial -- the proof of existence can tell us how to classify the associated computational problem. Something similar can be argued for PPA. Here the two existence theorems of interest are the Borsuk-Ulam theorem and its discretised version Tucker's lemma. The Borsuk-Ulam theorem says that every continuous function $$f$$ from an $$n$$-sphere to Euclidean $$n$$-space must map some pair of antipodal points (i.e., $$x$$ and $$-x$$) to the same point, while Tucker's lemma says that for any Tucker labelling (see [here](https://en.wikipedia.org/wiki/Tucker%27s_lemma)) of a triangulation of a closed ball, there must be an edge in the triangulation whose vertices are labelled by the same number with opposite signs. The characteristic problem for PPA is `LEAF`, which is similar to `EndOfALine` except now we want to find, given a leaf node as input, another leaf node in the exponentially large graph. `LEAF` is reducible to `TUCKER`, thus we may prove PPA-completeness by a reduction from `TUCKER`. Thus if the proof of existence of some object comes from the Borsuk-Ulam theorem or Tucker's lemma then it seems likely that the associated function problem would be PPA-complete.

$$
\texttt{LEAF} \le_p
\texttt{TUCKER} \le_p
\texttt{ConsensusHalving}, \texttt{NecklaceSplitting}, \texttt{OTHER}
$$

The final two examples are a bit hazier in my notes but involve the classes PLS and CLS (**C**ontinuous **L**ocal **S**earch). For the former if the proof of existence arises from a potential function argument then it suggests the function problem could be PLS-complete. Can't quite remember the existence proof for the latter, but since `GradientDescent` is complete for CLS = PPAD $$\cap$$ PLS I suppose it has something to do with finding a local minimum of some differentiable function.

It's always nice to end on some open questions -- a few I noted down (very poorly) from Aris' talk are: is finding an envy-free cutting of a cake PPAD-complete? How about splitting a necklace between two thieves? And from what I understand from my notes there is the question of similar things to be shown for [FIXP](https://complexityzoo.net/Complexity_Zoo:F#fixp). For a problem in FIXP we are given an algebraic circuit over $$\{+,-,*,/,\max,\min\}$$ with rational constants and $$n$$ variables that implements some continuous function and we are tasked with finding a fixed point.

### Part II: The `PureCircuit` Problem

The second part of the tutorial, given by Alexandros Hollender, mainly discussed a single problem which was recently shown to be PPAD-complete. In the `PureCircuit` problem[^4] we are given as input a Boolean circuit which may have cycles and nodes which take labels in $$\{ 0,1,\bot \}$$. The goal is to satisfy every gate in the circuit by assigning the correct labels to its input and output nodes. Since the labels are not Booleans (we interpret $$\bot$$ as "garbage") we enhance the definitions of the standard gates ($$\texttt{NOT}$$, $$\texttt{AND}$$, and $$\texttt{OR}$$) to handle these and introduce a new gate `PURIFY` that can remove garbage inputs. For example, the outputs of the standard gates remain unchanged when fed pure inputs, $$\texttt{NOT}(\bot)$$ can be anything, and $$\texttt{OR}(1,x) = 1$$ for any $$x \in \{ 0,1,\bot \}$$. This last definition exhibits an important notion of *robustness* which allows the gate to "short-circuit". It turns out this is required to make the problem interesting, otherwise it becomes polynomial-time solvable. The new `PURIFY` gate takes one input and returns two outputs that ensures that its possibly impure input is made pure: we have $$\texttt{PURIFY}(0) = (0,0)$$ and $$\texttt{PURIFY}(1) = (1,1)$$, while for $$\texttt{PURIFY}(\bot)$$ at least one of the outputs must be in $$\{0,1\}$$.

In addition to robustness there are three requirements for the problem to be interesting:
1. **The circuit may have cycles:** otherwise we could just simulate the circuit to find the correct labels
2. **Nodes take labels in $$\{ 0,1,\bot \}$$:** otherwise not all instances would have a solution (consider what would happen if three `NOT` gates were connected in a cycle).
3. **The circuit may contain `PURIFY` gates:** otherwise we can solve each instance trivially by just assigning garbage.

What's interesting about this problem is that not only is it fairly simple to understand, but the hardness does not come from the size of the instance -- recall `EndOfALine` requires exponential-sized graphs to be difficult otherwise we could just search the graph in polynomial time -- but from finding the correct labels for the nodes.

The remainder of this part of the tutorial went over the gist of a reduction from `PURIFY` to some form of bi/polymatrix games, but my notes get pretty thin so I'll leave it here and point you to the [paper](https://arxiv.org/abs/2209.15149).

## Tutorial 2: _Fair Division of the Indivisibles_

The second tutorial of the day was given by Rohit Vaish and was concerned with challenges in fairly allocating a set of indivisible items amongst agents. In this setting we have a collection of agents $$[n]$$ for whom we wish to compute an allocation $$A=(A_1,\ldots,A_n)$$ where $$A_i \subseteq 2^M$$, where $$M$$ is a set of indivisible items. Moreover each agent $$i$$ has a personal valuation for each of the individual items. Ordinarily agents would then have a valuation function $$v_i : 2^M \to \mathbb{R}$$ mapping bundles of items to a valuation for that bundle, but in this tutorial the assumption is that the valuation functions are additive. In other words, the total utility an agent derives from a bundle is simply the sum of her valuations for each item in that bundle. The tutorial also dealt with three types of items: *goods*, which add to the total valuation of any bundle; *chores*, which detract from the total valuation of any subset; and *mixed items*, which capture the remaining items.

### Part I: Computing envy-free allocations efficiently 

How do we quantify fairness? As a starting point we can start with envy-freeness, which says that given some allocation $$A$$ each agent $$i$$ prefers her own bundle $$A_i$$ to each other agent $$j$$'s bundle. In symbols the allocation $$A$$ is envy-free (EF) if $$v_i(A_i) \ge v_i(A_j)$$ for all $$j \neq i$$ for every agent $$i$$. Now a problem with this notion of fairness is that an EF allocation might not exist for every instance -- consider what happens when we have two agents and a single indivisible item -- and moreover it is NP-hard to decide if such an allocation exists. As a relaxation of envy-freeness we next consider envy-freeness up to one good, which says that although an allocation might not be envy-free, there always exists an item in another agent's bundle such that removing the item removes the envy the agent has over the other. In symbols for allocation $$A$$ to be envy-free up to one good (EF1) we must have $$v_i(A_i) \ge v_i(A_j \setminus \{g\})$$ for some $$g \in A_j$$ for every $$j \neq i$$ and every agent $$i$$. This *is* guaranteed to exist and is efficiently computable via e.g. the Round Robin algorithm (for additive valuations).[^5]

If we have even a slightly more general class of valuation functions known as monotone valuations -- where the total valuation for bundle $$S$$ is at least as much as the total valuation for bundle $$T$$ whenever $$S$$ is a superset of $$T$$ -- then we can still compute EF1 allocations efficiently using the [envy-cycle elimination](https://en.wikipedia.org/wiki/Envy-graph_procedure) algorithm. This works by assigning an unallocated good to an agent that no one envies, and otherwise swapping all pairs of envied items amongst agents until such an agent appears, and repeating this procedure until all goods are allocated. This can be modified slightly to work with chores as well, using top-trading envy-cycle elimination.

The overall takeaway of the first part was that when we have additive valuations round-robin can compute an EF1 allocation efficiently for both goods and chores, while efficient algorithms exist for computing such allocations with the slightly more general monotone valuations with the envy-cycle elimination and top-trading envy-cycle elimination algorithms. These also work with some modifications for instances with both goods and chores.

### Part II: Computing envy-free allocations efficiently 

Why might envy-freeness up to one good be undesirable? Consider allocating two doughnuts and a Ferrari to two agents who both (unsurprisingly) value the car more than the doughnut, and suppose we give one agent a doughnut and the other a doughnut and the Ferrari. This allocation is EF1, since we can remove the car from the allocation and the envy is removed, but it doesn't actually seem very *fair*. 

EF1 can be strengthened slightly to envy-freeness up to any good, which says that the envy over another agent's bundle can be resolved by removing *any* good from their allocation. Thus $$A$$ is envy-free up to any good (EFX) if $$v_i(A_i) \ge v_i(A_j \setminus \{g\})$$ for every $$g \in A_j$$ for all $$j \neq i$$ for all $$i$$. Note that this is stronger than EF1 since for an EF1 allocation we can remove the most valuable item (in the eyes of agent $$i$$) from agent $$j$$ to resolve agent $$i$$'s envy, while EFX requires envy-freeness to hold after we remove *any* item from agent $$j$$. Now, for identical agents with additive valuations an EFX allocation always exists an can be efficiently computed -- just allocate the goods in non-increasing order of (identical) values, giving each new good to the least-happy agent. The most recently allocated good is the least valued among all agents, and the allocation is EF up to the most recent good, and hence EFX. Relaxing the additive valuations to monotone, an EFX allocation still always exists for identical agents, but might not be efficiently computable. The results get slightly more complicated as agents become non-identical agents. Another variation of EFX is introduce charity, where an allocation may now leave behind a pool of unallocated items so long as no agent envies the pool. For monotone valuations, such an allocation always exists. 

Again we can extend EFX to work with chores, which introduces a few obstacles. Firstly, resolving arbitrary envy cycles can break EFX but choosing the right cycles to eliminate is not straightforward. If we consider a mixed setting of goods and chores then EFX allocations can fail to exist. One nice open question is the complexity of deciding an EFX allocation exists in such a setting. 

Again my notes seem to dwindle towards the end of the tutorial, but it mainly revolved around two more notions of fairness and efficiency in Pareto Optimality and Nash Social Welfare. An allocation is Pareto Optimal (PO) if we can only make an agent better off if another agent suffers because of it, while an allocation is Nash optimal if it maximises the Nash Social Welfare defined as $$\text{NSW}(A) = ( \prod_i v_i(A_i) )^{1/n}$$, i.e. the geometric mean of the agents' valuations. Any Nash optimal allocation is PO and EF1, but maximising Nash Social Welfare is APX-hard. This is not necessarily bad news, since an EF1 and PO allocation can at least be computed in [pseudopolynomial time](https://en.wikipedia.org/wiki/Pseudo-polynomial_time), where the runtime is polynomial in the numeric value of the input (the valuations) but not necessarily the number of bits required to represent it.

## Invited Talks and Paper Presentations

The remaining three days of the conference began with an hour long invited talk with the rest of the day dedicated to shorter presentations on the accepted papers. Particularly interesting among these was *Algorithmic Game Theory Meets Behavioural Economics* by Sigal Oren which, building on some observations from a paper[^6] in Econometrica 2019 that agents only collect about a quarter of the gains available from lying, introduced a model for moral agents. In particular players in $$\alpha$$-moral mechanisms will only lie when the benefit from doing so is at least an $$\alpha$$ factor of the sum of resulting losses of the other players, for $$\alpha \in [0,1]$$. Setting $$\alpha = 0$$ we recover strategyproofness (as here agents will lie when the gain is at least zero) while $$\alpha = 1$$ means players only lie if they gain at least the damage they cause to the other players. Intuitively, moral mechanisms extend the class of implementable allocation functions, and also allows auctioneers to leverage the morality of the bidders to extract more revenue.

With regards to the paper presentations there were quite a few I found particularly interesting, for a number of different reasons. Three papers from the broadly mechanism design focused session 

This report has been written in fulfilment of the conditions set by the King's [Student Opportunity Fund](https://www.kcl.ac.uk/students/apply-for-funding-through-the-student-opportunity-fund). 

## Footnotes

[^1]: Take Boolean satisfiability for example. Consider some Boolean formula $$\phi$$. The decision problem `SAT` asks "does there exist an assignment of truth values to Boolean variables such that $$\phi$$ evaluates to true?", while the function problem `FSAT` asks "find an assignment such that $$\phi$$ is satisfied, or otherwise tell me that no such assignment exists".

[^2]: First recall that a problem $$L$$ is $$A$$-hard for some class $$A$$ if it is "at least as hard as every problem in that class". Slightly more formally, $$L$$ is $$A$$-hard if for all $$L' \in A$$ there is a polynomial reduction $$f$$ from $$L'$$ to $$L$$ such that $$x \in L'$$ if and only if $$f(x) \in L$$. Language $$L$$ is $$A$$-complete if both $$L \in A$$ and $$L \in A$$-complete.

[^3]: A strategy profile $$x$$ where the benefit each player gets from a unilateral deviation from profile $$x$$ is no more than $$\varepsilon$$.

[^4]: See [`Pure-Circuit`: Strong Inapproximability for PPAD](https://arxiv.org/abs/2209.15149) for more details.

[^5]: My notes warn that social welfare may be bad though as Pareto Optimality, quite a weak notion of fairness, is not guaranteed by Round Robin. An allocation $$A$$ is Pareto Optimal if there is no other allocation $$A'$$ such that $$v_i(A_i') \ge v_i(A_i)$$ for all $$i$$ with the inequality strict for at least one $$i$$.

[^6]: Johannes Abeler, Daniele Nosenzo, and Collin Raymond, [*Preferences for Truth-Telling*](https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA14673), Econometrica 2019
